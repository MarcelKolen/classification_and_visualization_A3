{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c364e5f",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "## JuPyter Notebook - Verschuur L. 1811053, Kolenbrander M. 1653415"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88a6682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "\n",
    "# Convert numeric values into ranged representations\n",
    "convert_to_range = True\n",
    "# Represent ranges as categorical values or rounded to nearest base value: 12, b=5 -> 10-14\n",
    "range_categorical = False\n",
    "# Convert categorical values (not from ranged values) into one hot representations:\n",
    "# {'smoking': ['sometimes', 'regularly', 'sometimes', 'never']} -> \n",
    "# {'smoking_sometimes': [1, 0, 1, 0], 'smoking_regularly': [0, 1, 0, 0], 'smoking_never': [0, 0, 0, 1]}\n",
    "convert_categorical_to_one_hot = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db58073",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "971d9a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def round_to_base(in_val, base):\n",
    "    \"\"\"\n",
    "    Round the in_val value to the nearest base.\n",
    "    E.g. base 5\n",
    "        2  -> 0\n",
    "        9  -> 10\n",
    "        12 -> 10\n",
    "        13 -> 15\n",
    "    \n",
    "    :param in_val: Value to round\n",
    "    :param base: Base to round to\n",
    "    :return: Rounded value\n",
    "    \"\"\"\n",
    "    \n",
    "    return round(in_val/base) * base\n",
    "\n",
    "def floor_range(in_val, range_val):\n",
    "    \"\"\"\n",
    "    Floor the in_val value to the nearest base (range_val). \n",
    "    And then indicate a range.\n",
    "    E.g. base 5\n",
    "        2  -> 0 - 4\n",
    "        9  -> 5 - 9\n",
    "        12 -> 10 - 14\n",
    "        13 -> 10 - 14\n",
    "    \n",
    "    :param in_val: Value to round\n",
    "    :param range_val: Range to floor to\n",
    "    :return: Rounded value range\n",
    "    \"\"\"\n",
    "    \n",
    "    floored_val = math.floor(in_val/range_val) * range_val\n",
    "    \n",
    "    return f\"{floored_val} - {floored_val + range_val - 1}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cf00f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_column_names(df, find_column_name):\n",
    "    \"\"\"\n",
    "    Find all columns in a dataframe based on a prefix (find_column_name) and return as a list.\n",
    "    E.g. columns: [\"a_a\", \"a_b\", \"b_a\", \"c\"] and find_column_name: \"a\"\n",
    "        [\"a_a\", \"a_b\"]\n",
    "    \n",
    "    :param df: Input data frame\n",
    "    :param find_column_name: Prefix of column name\n",
    "    :return: Rounded value range\n",
    "    \"\"\"\n",
    "    \n",
    "    return [column_name for column_name in df.columns if f\"{find_column_name}_\" in column_name ]\n",
    "\n",
    "def fetch_columns_on_name_list(df, find_column_name_list):\n",
    "    \"\"\"\n",
    "    Find all subsets of the prefixes provided in find_column_name_list and form a list of these.\n",
    "    The columns are found with find_column_names.\n",
    "    \n",
    "    :param df: Input data frame\n",
    "    :param find_column_name_list: List of prefix column names\n",
    "    :return: Rounded value range\n",
    "    \"\"\"\n",
    "    \n",
    "    return [name for name_group in [find_column_names(df, column_name) for column_name in find_column_name_list] for name in name_group]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ed9688",
   "metadata": {},
   "source": [
    "## Data fetching & Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "868f0b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = \"healthcare-dataset-stroke-data.csv\"\n",
    "\n",
    "# Fetching CSV and converting to data frame\n",
    "data_file = pd.read_csv(file_path, header=0)\n",
    "\n",
    "# Drop all entries with nan values\n",
    "data_file = data_file.dropna()\n",
    "\n",
    "# Convert interval and ratio variables into ranges\n",
    "if convert_to_range and range_categorical:\n",
    "    data_file.insert(data_file.columns.get_loc(\"age\"), \"ranged_age\", [floor_range(age, 10) for age in data_file[\"age\"]])\n",
    "    data_file.insert(data_file.columns.get_loc(\"avg_glucose_level\"), \"ranged_avg_glucose_level\", [floor_range(avg_glucose_level, 25) for avg_glucose_level in data_file[\"avg_glucose_level\"]])\n",
    "    data_file.insert(data_file.columns.get_loc(\"bmi\"), \"ranged_bmi\", [floor_range(bmi, 2) for bmi in data_file[\"bmi\"]])\n",
    "elif convert_to_range and not range_categorical:\n",
    "    data_file.insert(data_file.columns.get_loc(\"age\"), \"ranged_age\", [round_to_base(age, 10) for age in data_file[\"age\"]])\n",
    "    data_file.insert(data_file.columns.get_loc(\"avg_glucose_level\"), \"ranged_avg_glucose_level\", [round_to_base(avg_glucose_level, 25) for avg_glucose_level in data_file[\"avg_glucose_level\"]])\n",
    "    data_file.insert(data_file.columns.get_loc(\"bmi\"), \"ranged_bmi\", [round_to_base(bmi, 2) for bmi in data_file[\"bmi\"]])\n",
    "\n",
    "data_file.insert(data_file.columns.get_loc(\"bmi\"), \"rounded_bmi\", data_file[\"bmi\"].round(0))\n",
    "    \n",
    "# Convert \"boolean\" variables into true boolean variables\n",
    "data_file[\"hypertension\"] = data_file[\"hypertension\"].astype(\"bool\")\n",
    "data_file[\"heart_disease\"] = data_file[\"heart_disease\"].astype(\"bool\")\n",
    "data_file[\"stroke\"] = data_file[\"stroke\"].astype(\"bool\")\n",
    "data_file[\"ever_married\"] = np.where(data_file[\"ever_married\"] == \"Yes\", True, False).astype(\"bool\")\n",
    "    \n",
    "# Convert categorical variables into a one-hot representation\n",
    "if convert_categorical_to_one_hot:\n",
    "    data_file = pd.concat([data_file, pd.get_dummies(data_file[\"gender\"], prefix=\"gender\")], axis=1)\n",
    "    data_file = pd.concat([data_file, pd.get_dummies(data_file[\"work_type\"], prefix=\"work_type\")], axis=1)\n",
    "    data_file = pd.concat([data_file, pd.get_dummies(data_file[\"Residence_type\"], prefix=\"Residence_type\")], axis=1)\n",
    "    data_file = pd.concat([data_file, pd.get_dummies(data_file[\"smoking_status\"], prefix=\"smoking_status\")], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11e2f78",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839e958b",
   "metadata": {},
   "source": [
    "### Test & Train set generation\n",
    "**Applied algorithms for this test and training set**\n",
    "- SKLearn Random Forest Classifier\n",
    "- SKLearn Support Vector Classification Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dfa3c87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Decision Variables\n",
    "X = data_file.loc[:,[\"ranged_age\", \"hypertension\", \"heart_disease\", \"ever_married\", \"ranged_avg_glucose_level\", \"rounded_bmi\", *fetch_columns_on_name_list(data_file, [\"work_type\"])]].values\n",
    "# Target Variable\n",
    "y = data_file.loc[:,\"stroke\"].values\n",
    "\n",
    "# Split datasets into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale data for classifiers\n",
    "X_train_scaled = sc.fit_transform(X_train)\n",
    "X_test_scaled = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b236dc",
   "metadata": {},
   "source": [
    "### Random Forest training & testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5cfa9e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=150, n_jobs=-1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=150, n_jobs=-1)\n",
    "rf_classifier.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "63be7f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# # # Classification report # # #\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.98      0.97       469\n",
      "        True       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.94       491\n",
      "   macro avg       0.48      0.49      0.48       491\n",
      "weighted avg       0.91      0.94      0.93       491\n",
      "\n",
      "# # # Confusion matrix # # #\n",
      "[[461   8]\n",
      " [ 22   0]] \n",
      "\n",
      "# # # Accuracy score # # #\n",
      "0.9389002036659878\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "rf_y_prediction = rf_classifier.predict(X_test_scaled)\n",
    "\n",
    "print(\"# # # Classification report # # #\")\n",
    "print(classification_report(Y_test, rf_y_prediction))\n",
    "\n",
    "print(\"# # # Confusion matrix # # #\")\n",
    "print(confusion_matrix(Y_test, rf_y_prediction), \"\\n\")\n",
    "\n",
    "print(\"# # # Accuracy score # # #\")\n",
    "print(accuracy_score(Y_test, rf_y_prediction), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd72cae",
   "metadata": {},
   "source": [
    "### Support Vector Classification training & testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c787d7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "SV_classifier = SVC()\n",
    "SV_classifier.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "84380693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# # # Classification report # # #\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      1.00      0.98       469\n",
      "        True       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.96       491\n",
      "   macro avg       0.48      0.50      0.49       491\n",
      "weighted avg       0.91      0.96      0.93       491\n",
      "\n",
      "# # # Confusion matrix # # #\n",
      "[[469   0]\n",
      " [ 22   0]] \n",
      "\n",
      "# # # Accuracy score # # #\n",
      "0.955193482688391 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "SV_y_prediction = SV_classifier.predict(X_test_scaled)\n",
    "\n",
    "print(\"# # # Classification report # # #\")\n",
    "print(classification_report(Y_test, SV_y_prediction))\n",
    "\n",
    "print(\"# # # Confusion matrix # # #\")\n",
    "print(confusion_matrix(Y_test, SV_y_prediction), \"\\n\")\n",
    "\n",
    "print(\"# # # Accuracy score # # #\")\n",
    "print(accuracy_score(Y_test, SV_y_prediction), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba4ce6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
